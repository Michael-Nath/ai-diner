{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Testing with Deep Reinforcement Learning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DINING TIMES:\n"
     ]
    }
   ],
   "source": [
    "from envs.dining_hall_env import DiningHallEnv\n",
    "# SETUP PARAMETERS OF DINING HALL\n",
    "num_diners = 100\n",
    "num_dining_halls = 5\n",
    "num_dining_days = 7 # important for establishing specials probability for halls\n",
    "num_dining_times = 10\n",
    "env = DiningHallEnv(num_diners=num_diners, num_dining_halls=num_dining_halls, num_dining_days=num_dining_days, num_dining_times=num_dining_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiDiscrete([5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5])\n",
      "Dict(current_day:Discrete(7), unavailable_halls:MultiDiscrete([6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6\n",
      " 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6 6]))\n",
      "array([[0.20497554, 0.60269791, 0.5279855 , 0.14783359, 0.07459853,\n",
      "        0.29877446, 0.87111719],\n",
      "       [0.45654221, 0.8731332 , 0.48483085, 0.42216488, 0.80322738,\n",
      "        0.20052952, 0.38965143],\n",
      "       [0.89529731, 0.87672316, 0.82578997, 0.4252813 , 0.45541589,\n",
      "        0.6836752 , 0.19428943],\n",
      "       [0.51915442, 0.3650452 , 0.62922959, 0.03607705, 0.57794386,\n",
      "        0.63314045, 0.96676962],\n",
      "       [0.72136064, 0.96062419, 0.3544264 , 0.93021577, 0.20732983,\n",
      "        0.7226198 , 0.36804707]])\n"
     ]
    }
   ],
   "source": [
    "# Inspect Observation and Action Space\n",
    "pprint(env.action_space)\n",
    "pprint(env.observation_space)\n",
    "# We can also inspect (although our agent won't use it) the specials probability (useful for constructing some optimal policies)\n",
    "pprint(env.special_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.envs.registration import register\n",
    "import gym\n",
    "register(\n",
    "    id=\"DiningHall-v0\",\n",
    "    entry_point=DiningHallEnv\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DINING TIMES:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 4, 1, 2, 2, 1, 4, 0, 3, 0, 1, 0, 0, 2, 2, 0, 2, 4, 2, 4, 0,\n",
       "       4, 2, 4, 2, 0, 1, 2, 2, 4, 0, 2, 0, 0, 1, 1, 0, 2, 3, 0, 4, 1, 1,\n",
       "       3, 4, 3, 3, 0, 1, 1, 4, 4, 2, 2, 3, 4, 4, 4, 2, 1, 4, 2, 3, 0, 1,\n",
       "       0, 1, 3, 4, 2, 0, 4, 4, 0, 1, 0, 0, 4, 1, 1, 0, 2, 0, 2, 3, 1, 3,\n",
       "       4, 0, 3, 0, 3, 1, 4, 4, 3, 3, 1, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing if environment got registered\n",
    "test_env = gym.make('ai_diner/DiningHall-v0',num_diners=num_diners, num_dining_halls=num_dining_halls, num_dining_days=num_dining_days, num_dining_times=num_dining_times)\n",
    "test_env.action_space.sample()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are using off-the-shelf deep RL models provided by the Stable-Baselines library. Due to the environment setup, we are limited to only two deep RL Methods: A2C and PPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure our environment is compatible with Stable-Baselines\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "check_env(env, warn=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import A2C, PPO\n",
    "a2c_model = A2C(\"MultiInputPolicy\", env, verbose=1)\n",
    "ppo_model = PPO(\"MultiInputPolicy\", env, verbose=1)\n",
    "# model.learn(total_timesteps=10000, log_interval=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a2c_model.learn()\n",
    "\n",
    "\n",
    "\n",
    "model.save(\"a2c_diner\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = A2C.load(\"a2c_diner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0 2 2 4 1 2 3 1 2 2 4 0 2 4 2 1 1 3 3 4 1 2 0 3 2 1 0 0 1 2 1 1 0 0 1 0 4\n",
      " 1 3 4 1 0 2 3 4 2 2 0 0 0 1 3 3 3 1 3 0 2 1 2 4 2 4 1 2 1 2 4 3 1 2 0 3 1\n",
      " 4 4 1 4 4 1 4 4 0 4 0 3 4 2 1 3 1 2 2 0 0 0 4 2 4 0] 20.0\n",
      "1 [1 0 4 3 3 2 1 4 1 4 4 4 2 4 0 1 4 2 2 0 2 0 0 3 2 0 0 3 1 2 2 4 4 0 4 2 1\n",
      " 0 4 4 0 3 1 1 2 3 0 2 0 2 4 0 0 1 1 2 1 2 2 3 0 3 4 1 2 4 4 1 0 1 0 3 4 0\n",
      " 0 4 2 3 3 0 1 3 4 0 0 4 0 4 0 4 3 1 2 0 0 0 1 1 2 2] -25773.427604301447\n",
      "2 [1 1 4 2 3 0 0 2 1 3 3 4 4 2 4 2 3 1 3 1 2 4 4 2 2 4 4 0 2 3 3 3 3 1 4 4 4\n",
      " 0 0 1 3 2 3 3 1 0 1 3 0 2 4 4 2 1 3 4 1 4 3 1 0 3 1 1 2 1 0 1 2 1 0 4 4 0\n",
      " 4 0 3 3 0 4 4 0 2 1 4 4 0 0 1 1 3 1 0 3 0 2 2 3 1 4] -25574.097187210267\n",
      "3 [1 2 0 4 2 0 1 1 3 0 4 2 3 4 0 1 2 4 3 0 1 2 4 1 0 2 3 2 3 2 4 3 2 0 1 1 1\n",
      " 4 3 4 0 4 2 1 4 2 0 1 1 3 1 2 2 1 4 1 3 1 3 0 0 1 1 3 2 4 3 4 4 3 2 0 2 0\n",
      " 4 4 1 2 0 4 0 4 4 4 3 2 4 1 0 0 3 1 2 4 4 0 2 1 2 0] -28593.08306872006\n",
      "4 [2 2 0 0 1 2 1 1 3 4 4 3 2 4 0 3 3 2 2 3 2 0 2 0 0 4 3 0 1 4 3 4 2 2 1 1 4\n",
      " 2 0 4 2 4 0 3 4 2 2 1 0 2 4 3 4 1 3 3 3 2 3 1 3 3 2 2 2 1 3 4 2 0 4 0 2 1\n",
      " 3 4 0 1 2 4 1 3 3 1 0 3 4 2 1 0 3 0 3 1 3 4 2 1 2 4] -16923.194179831182\n",
      "5 [0 3 3 3 0 2 2 1 4 2 3 4 2 4 4 4 0 4 0 4 3 2 0 3 2 2 4 0 4 4 1 4 2 0 1 1 1\n",
      " 1 0 4 0 2 2 3 3 1 3 4 0 1 4 3 1 1 3 4 1 1 0 1 0 3 0 1 3 2 4 4 1 3 1 1 3 2\n",
      " 4 4 1 2 2 0 2 4 2 2 3 0 4 1 3 4 3 4 2 2 2 3 4 1 0 4] -33383.39162507375\n",
      "6 [2 0 1 4 2 1 1 4 4 0 0 2 2 3 0 1 2 2 4 4 2 0 0 4 2 2 3 0 3 3 3 0 1 1 3 1 4\n",
      " 3 0 4 2 4 4 1 3 0 3 2 0 4 3 4 3 3 0 2 1 2 0 0 4 3 1 1 2 1 4 4 1 1 0 3 4 2\n",
      " 0 4 1 2 2 4 1 3 3 2 3 4 4 3 2 0 3 1 3 4 3 0 0 0 3 0] -25963.15225436533\n",
      "0 [0 2 2 0 1 4 3 3 1 1 4 4 0 0 0 4 2 1 4 3 0 4 0 3 1 0 2 4 1 4 0 4 1 2 4 1 0\n",
      " 3 0 3 2 4 2 3 0 4 0 0 2 2 4 3 2 3 2 2 0 3 4 1 1 0 0 1 2 4 3 0 3 1 0 4 4 1\n",
      " 4 3 1 4 1 4 3 2 4 4 3 2 2 1 4 3 3 3 2 3 1 3 2 1 2 0] -28202.833249095238\n",
      "1 [0 2 0 4 3 2 4 2 1 1 4 2 0 4 4 1 2 4 2 1 2 1 0 3 2 3 2 3 4 4 0 4 0 0 1 0 0\n",
      " 0 4 4 4 2 3 3 4 2 1 0 0 2 1 3 3 4 4 2 3 2 4 1 4 0 1 1 3 2 4 1 1 4 4 2 4 2\n",
      " 4 4 3 0 1 4 4 0 3 2 4 4 4 3 1 4 3 1 2 3 3 4 2 2 2 1] -21002.790468346582\n",
      "2 [4 2 4 4 1 2 4 0 3 4 4 0 2 2 4 0 3 1 3 4 2 0 2 3 0 1 3 1 4 0 1 3 2 3 4 1 1\n",
      " 4 0 4 0 4 3 4 1 1 3 0 4 3 3 1 1 3 1 4 0 2 1 4 0 1 2 0 3 1 2 4 1 3 0 4 4 2\n",
      " 0 2 0 2 3 4 2 3 2 0 0 4 2 3 1 1 2 4 1 3 0 0 4 0 4 3] -30924.4246718463\n",
      "3 [1 0 0 0 2 3 1 4 0 4 3 0 2 2 4 1 0 2 4 3 1 2 3 3 2 1 0 2 1 1 3 4 3 4 0 4 1\n",
      " 0 1 3 3 0 2 0 3 0 3 0 0 2 2 0 1 4 0 4 3 2 2 3 4 1 2 1 2 4 2 1 3 1 0 0 2 1\n",
      " 0 3 3 2 1 1 2 3 3 2 2 4 4 1 1 0 3 1 2 3 4 3 2 2 2 4] -20973.053570154814\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "i = 0\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    day = obs[\"current_day\"]\n",
    "    print(day, action, rewards)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    i += 1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 55   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 36   |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 45            |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 89            |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5525729e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.17e+10      |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.0007       |\n",
      "|    value_loss           | 1.03e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 43            |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 141           |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1861557e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 5.96e-08      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.16e+10      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.000565     |\n",
      "|    value_loss           | 1.03e+11      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 42           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 194          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.065433e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 5.96e-08     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.42e+10     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.000528    |\n",
      "|    value_loss           | 1.06e+11     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 41            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 247           |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0170916e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.23e+10      |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.000523     |\n",
      "|    value_loss           | 1.03e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 41            |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 298           |\n",
      "|    total_timesteps      | 12288         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0317599e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.2e+10       |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -0.000525     |\n",
      "|    value_loss           | 1.03e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 40            |\n",
      "|    iterations           | 7             |\n",
      "|    time_elapsed         | 351           |\n",
      "|    total_timesteps      | 14336         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0809163e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.25e+10      |\n",
      "|    n_updates            | 60            |\n",
      "|    policy_gradient_loss | -0.000544     |\n",
      "|    value_loss           | 1.04e+11      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 40           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 401          |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.873474e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.1e+10      |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.000522    |\n",
      "|    value_loss           | 1.03e+11     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 40            |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 450           |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0891526e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.13e+10      |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -0.000538     |\n",
      "|    value_loss           | 1.03e+11      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 41           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 499          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.855721e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.16e+10     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00052     |\n",
      "|    value_loss           | 1.05e+11     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 41            |\n",
      "|    iterations           | 11            |\n",
      "|    time_elapsed         | 548           |\n",
      "|    total_timesteps      | 22528         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2750388e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.16e+10      |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -0.000583     |\n",
      "|    value_loss           | 1.02e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 40            |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 599           |\n",
      "|    total_timesteps      | 24576         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0873482e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.14e+10      |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -0.000542     |\n",
      "|    value_loss           | 1.02e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 40            |\n",
      "|    iterations           | 13            |\n",
      "|    time_elapsed         | 650           |\n",
      "|    total_timesteps      | 26624         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0986696e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.96e+10      |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -0.000542     |\n",
      "|    value_loss           | 1.03e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 40            |\n",
      "|    iterations           | 14            |\n",
      "|    time_elapsed         | 700           |\n",
      "|    total_timesteps      | 28672         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1952361e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | -1.19e-07     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.15e+10      |\n",
      "|    n_updates            | 130           |\n",
      "|    policy_gradient_loss | -0.000569     |\n",
      "|    value_loss           | 1.02e+11      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 40           |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 751          |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.707583e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.02e+10     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.000511    |\n",
      "|    value_loss           | 1.03e+11     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 1689          |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0650256e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 1.19e-07      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.3e+10       |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -0.000537     |\n",
      "|    value_loss           | 1.03e+11      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 6            |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 5446         |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.158216e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.14e+10     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.000556    |\n",
      "|    value_loss           | 1.03e+11     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 6             |\n",
      "|    iterations           | 18            |\n",
      "|    time_elapsed         | 5501          |\n",
      "|    total_timesteps      | 36864         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0321673e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.2e+10       |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | -0.000533     |\n",
      "|    value_loss           | 1.05e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 6             |\n",
      "|    iterations           | 19            |\n",
      "|    time_elapsed         | 5559          |\n",
      "|    total_timesteps      | 38912         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0630756e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.17e+10      |\n",
      "|    n_updates            | 180           |\n",
      "|    policy_gradient_loss | -0.000538     |\n",
      "|    value_loss           | 1.04e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 7             |\n",
      "|    iterations           | 20            |\n",
      "|    time_elapsed         | 5613          |\n",
      "|    total_timesteps      | 40960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0782096e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.31e+10      |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | -0.000541     |\n",
      "|    value_loss           | 1.04e+11      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 7             |\n",
      "|    iterations           | 21            |\n",
      "|    time_elapsed         | 5670          |\n",
      "|    total_timesteps      | 43008         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0763179e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.2e+10       |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | -0.000532     |\n",
      "|    value_loss           | 1.03e+11      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 7            |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 5724         |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.076929e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.15e+10     |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00054     |\n",
      "|    value_loss           | 1.03e+11     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 8            |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 5779         |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.743962e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | -1.19e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.17e+10     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.000524    |\n",
      "|    value_loss           | 1.03e+11     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 8            |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 5839         |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.025357e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -161         |\n",
      "|    explained_variance   | 0            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.2e+10      |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.000527    |\n",
      "|    value_loss           | 1.04e+11     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 8             |\n",
      "|    iterations           | 25            |\n",
      "|    time_elapsed         | 5890          |\n",
      "|    total_timesteps      | 51200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.1473021e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -161          |\n",
      "|    explained_variance   | 0             |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.89e+10      |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | -0.000552     |\n",
      "|    value_loss           | 1.01e+11      |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "model = PPO(\"MultiInputPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=50000)\n",
    "model.save(\"ppo_diner\")\n",
    "\n",
    "del model # remove to demonstrate saving and loading\n",
    "\n",
    "model = PPO.load(\"ppo_diner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 4 4 1 3 4]\n",
      "0 [1] 10.0\n",
      "1 [1] 20.0\n",
      "2 [3] -990.0\n",
      "3 [1] 20.0\n",
      "4 [2] 20.0\n",
      "5 [3] 10.0\n",
      "6 [1] 20.0\n",
      "0 [0] 20.0\n",
      "1 [1] 20.0\n",
      "2 [2] 20.0\n",
      "3 [4] 10.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "obs = env.reset()\n",
    "i = 0\n",
    "print(np.argmax(info[\"special_probs\"], axis=0))\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    day = obs[\"current_day\"]\n",
    "    print(day, action, rewards)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    i += 1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.68048739 0.58412807 0.94703602 0.42349863 0.69825954 0.0272923\n",
      "  0.38269711]\n",
      " [0.9148012  0.88536284 0.80473278 0.33527957 0.86038846 0.65524026\n",
      "  0.55762551]\n",
      " [0.07373496 0.35836562 0.06491196 0.87533902 0.04280173 0.40592098\n",
      "  0.41552788]\n",
      " [0.49079895 0.10607619 0.6842602  0.35562208 0.37553194 0.66906777\n",
      "  0.70639979]\n",
      " [0.2722031  0.17432987 0.96813667 0.881014   0.68859568 0.46819329\n",
      "  0.94272305]]\n",
      "[1 1 4 4 1 3 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(info[\"special_probs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-diner-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
